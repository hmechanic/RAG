{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3420c327-c84e-4174-8562-55d81b00b01b",
   "metadata": {},
   "source": [
    "# RAG Recursive Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d55782-8365-4957-b023-aa6551951a09",
   "metadata": {},
   "source": [
    "## Required API Keys\n",
    "\n",
    "Before running this script, you **must** obtain API keys for the following services and configure them as environment variables:\n",
    "\n",
    "1.  **`GEMINI_API_KEY`**: Your API key for Google Gemini.\n",
    "2.  **`GROQ_API_KEY`**: Your API key for [Groq](https://groq.com/).\n",
    "3.  **`LLAMA_CLOUD_API_KEY`**: Your API key for [Llama Cloud](https://cloud.llamaindex.ai/login.)\n",
    "\n",
    "**Configuration:**\n",
    "\n",
    "The script uses `python-dotenv` to load these keys. Create a file named `.env` in the same directory as the script and add your keys like this:\n",
    "\n",
    "```plaintext\n",
    "GEMINI_API_KEY=\"YOUR_GEMINI_API_KEY_HERE\"\n",
    "GROQ_API_KEY=\"YOUR_GROQ_API_KEY_HERE\"\n",
    "LLAMA_CLOUD_API_KEY=\"YOUR_LLAMA_CLOUD_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ee92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from ingest_documents import convert_pdf\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Now try to get the key\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"Please set the GEMINI_API_KEY environment variable.\")\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"Please set the GROQ_API_KEY environment variable.\")\n",
    "\n",
    "    \n",
    "if \"LLAMA_CLOUD_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"Please set the LLAMA_CLOUD_API_KEY environment variable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76275cb6-7aac-4909-ac92-32fc059f264a",
   "metadata": {},
   "source": [
    "## Load LLM's from groq\n",
    "```\n",
    "pip install torch torchvision torchaudio\n",
    "pip install --upgrade jupyter ipywidgets\n",
    "pip install llama-index-llms-groq\n",
    "pip install llama-index-embeddings-huggingface\n",
    "pip install llama-index-embeddings-instructor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f94010-c688-4809-8bad-98798d9dce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "llm = Groq(model=\"qwen-qwq-32b\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bce537-f992-4ad9-a464-3abfe9c3b996",
   "metadata": {},
   "source": [
    "## Embedding Model\n",
    "\n",
    "An embed model is used to convert text into numerical vectors (embeddings) that capture the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d5954b7-0dba-44bd-86f9-9084c36bd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"intfloat/multilingual-e5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c57e0c-8211-4fcc-a67e-a0ec9bfbe84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff35c29a37f4d898152282e21c282ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e48855d9894755a515628de905b82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f75b56a623e4d9eb4fcd88ae652c538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b67779c1bc4be794d63ae76ce4d43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1716532375634785b8e42bc6056028dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d41df1996784a46a79fee084dbea7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7709e8e132d42c18301a2315cb6bdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f00d1978b70470bb35d4bdbc6a09e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891892ee12284d92a50a28d1b3f8b451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b09602e5830461ea4f358fb33d67efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "import torch\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=model_name,\n",
    "    embed_batch_size=32,  # Adjust based on your RAM\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ced6f-61b8-4d9b-accf-8cf9b6366460",
   "metadata": {},
   "source": [
    "## From Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb548e79-de35-4817-8204-ff4914049b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_cloud_services import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser, get_leaf_nodes\n",
    "from llama_index.core.retrievers import RecursiveRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50de3359-918d-4cbe-bac9-e646bb2eb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"./input_files/parsing_prube.pdf\"\n",
    "OUTPUT_DIR = \"./output_files/\" # YOU will save the file here\n",
    "\n",
    "markdown_document_path = convert_pdf(PDF_PATH, OUTPUT_DIR, gemini_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edd6579a-39b1-4362-8ba2-0cf811504931",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    documents = SimpleDirectoryReader(input_files=[markdown_document_path]).load_data()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Markdown file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6558b2c6-7407-423b-8fc8-f1ae8c82ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 512, 128] # Adjust these based on your content!\n",
    "                                 # Larger numbers for bigger parent chunks.\n",
    ")\n",
    "\n",
    "all_nodes = node_parser.get_nodes_from_documents(documents)\n",
    "leaf_nodes = get_leaf_nodes(all_nodes) # These are the smallest child nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e43d85b-eb6e-4a92-b34d-d9956e891928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len documets: 1\n",
      "Total nodes created: 12\n",
      "Leaf nodes created: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total len documets: {len(documents)}\")\n",
    "print(f\"Total nodes created: {len(all_nodes)}\")\n",
    "print(f\"Leaf nodes created: {len(leaf_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced001ab-7ad8-4970-97f4-4eeb4a048aff",
   "metadata": {},
   "source": [
    "## Setup ChromaDB\n",
    "\n",
    "Se configura una base de datos vectorial utilizando **ChromaDB**\n",
    "\n",
    "### Embedding models from HiggingFace\n",
    "\n",
    "*Windows:*v2\n",
    "ensure that have installed Microsoft c++ build tools, if not: \n",
    "Open powershell as administrator and run:\n",
    "```\n",
    "Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n",
    "\n",
    "choco install visualstudio2022buildtools -y\n",
    "```\n",
    "Note: in windows you have to configure visual studio build tool with windows 10 SDK - MSVC v142 - VS 2019 C++ x64/x86 build tools and C++ CMake Tools for Windows.\n",
    "Then in your environment terminal:\n",
    "```\n",
    "pip install chromadb\n",
    "pip install llama-index-vector-stores-chroma\n",
    "```\n",
    "### Aviable models tested\n",
    "- BGE-m3\n",
    "- E5-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abd4c95f-06ca-495a-a5bd-b0efdedffed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35d056f4-7986-46a6-a8ba-77211834524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client\n",
    "vector_db = chromadb.PersistentClient(path=\"./databases/prube_RecursiveRetrieve_cromadb_v1\")\n",
    "chroma_collection = vector_db.get_or_create_collection(\"prube\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442ffd6-6ac4-43f2-b865-84ae0c2838e2",
   "metadata": {},
   "source": [
    "## MongoDB docstore database\n",
    "\n",
    "Download mongoDB:\n",
    "https://www.mongodb.com/try/download/community\n",
    "\n",
    "```\n",
    "pip install llama-index-storage-docstore-mongodb\n",
    "\n",
    "pip install llama-index-storage-index-store-mongodb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9804594-7e6e-40a1-98e3-7d184c32decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n",
    "from pymongo import MongoClient  \n",
    "\n",
    "\n",
    "\n",
    "database_name = \"nexos_RecursiveRetrieve_v1\" # Nombre de la base de datos\n",
    "mongo_uri = f\"mongodb://127.0.0.1:27017/{database_name}\"  # Database name in URI\n",
    "\n",
    "mongo_docstore = MongoDocumentStore.from_uri(\n",
    "    uri=mongo_uri,\n",
    "    db_name=database_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d281478d-2d3d-45fb-9609-1b8212627bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=mongo_docstore, \n",
    "    vector_store=vector_store\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0588abbd-1510-41b1-be2f-377cc24a4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context.docstore.set_document_hash(documents[0].id_, documents[0].hash) # For the main doc\n",
    "storage_context.docstore.add_documents(all_nodes, allow_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b44324-4eec-4940-b75b-f3c4e8077f0c",
   "metadata": {},
   "source": [
    "## Index Data \n",
    "\n",
    "* get_page_nodes:\n",
    "  - Función que divide cada documento en \"nodos\" (fragmentos) utilizando un separador (\\n---\\n en este caso).\n",
    "  - Cada fragmento se convierte en un TextNode: contiene el texto y los metadatos del documento original.\n",
    "* MarkdownElementNodeParser:\n",
    "  - Es un parser especializado en dividir documentos Markdown en elementos estructurados (como párrafos, encabezados, listas, etc.).\n",
    "  - Utiliza un modelo de lenguaje (LLM) para ayudar en el proceso de parsing.\n",
    "* get_nodes_from_documents:\n",
    "  - get_nodes_from_documents: Aplica el parser a los documentos para generar nodos estructurados.\n",
    "* get_nodes_and_objects: ara procesar los nodos (nodes) y generar dos tipos de salidas.\n",
    "  - base_nodes: Son los nodos principales que contienen el contenido textual dividido en fragmentos más pequeños.\n",
    "  - objects: Elementos estructurados adicionales que pueden incluir metadatos, relaciones entre nodos u otra información derivada del parsing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a231749f-6773-47ef-a3d5-72ca473ed684",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(\n",
    "    leaf_nodes, # Index the leaf nodes for initial retrieval\n",
    "    storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b8c911b-b2e7-4e04-b6b0-9cf76523ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base retriever for the leaf nodes\n",
    "base_retriever = vector_index.as_retriever(similarity_top_k=5) # Retrieve top 5 leaf nodes\n",
    "\n",
    "# The node_dict should contain all nodes (parents and children)\n",
    "# so the retriever can look up parent nodes by their IDs.\n",
    "node_dict = {node.node_id: node for node in all_nodes}\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    'vector', # A name for the root retriever type\n",
    "    retriever_dict={'vector': base_retriever},\n",
    "    node_dict=node_dict,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3742d-bd4c-4e12-8130-dfb9c6d6f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# --- 6. Create Query Engine ---\n",
    "\n",
    "# Create the alternative reranker\n",
    "reranker = SentenceTransformerRerank(\n",
    "    top_n=5,  # Changed from top_n to top_k based on the API\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # This is a good alternative model for reranking\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    recursive_retriever,\n",
    "    node_postprocessors=[reranker]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7aa56d6f-7324-4238-a873-f226a640c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What does mean passenger VKM in the model? and why is raletd with the PKM with a convertion factor of 1.5\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: The car is labeled as \"Car CAR\" in the center of a rectangle. On the left side of the rectangle is \"DSL\" and \"Activity in 'vehicle kilometers' VKM\". On the right side of the rectangle is \"TX1\" and \"Commodity unit 'Passenger kilometers' PKM\". Below the rectangle is \"Capacity in '# of cars' NOC\". Below the diagram are the following equations: \"Definition of process activity PRC\\_ACTUNT(r,p,cg,u) = {UTOPIA.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Since the capacity and activity units are different (mtoe for the capacity and PJ for the activity), the user has to supply the conversion factor from the energy unit embedded in the capacity unit to the activity unit. This is done by specifying the parameter **prc\\_capact(r,p)**. In the example **prc\\_capact** has the value 41.868.\n",
      "\n",
      "Image /page/0/Figure/1 description: The image shows a diagram of a refinery process.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: **Figure 3: Example of the definition of the capacity unit**\n",
      "\n",
      "It might occur that the unit in which the commodity(ies) of the primary commodity group are measured, is different from the activity unit. An example is shown in Figure 4. The activity of the transport technology CAR is defined by commodity TX1, which is measured in passenger kilometres PKM. The activity of the process is, however, defined in vehicle kilometres VKM, while the capacity of the process CAR is defined as number of cars NOC.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: p,cg,u) = {UTOPIA.CAR.TX1.PKM}\", \"Definition of capacity unit PRC\\_CAPUNT(r,p,cg,u) = {UTOPIA.CAR.TX1.NOC}\", \"Conversion factor from capacity to activity unit PRC\\_CAPACT UTOPIA, CAR = 10000\", and \"Conversion factor from activity unit to commodity unit PRC\\_ACTFLO UTOPIA, 2000,CAR,TX1 = 1.5\".\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: An arrow points from \"Commodity group CG\\_SRE\" to the two blue lines. The image also includes the following text: \"Definition of capacity unit PRC\\_CAPUNT(r,p,cg,u) = {UTOPIA.SRE.CG\\_SRE.MTOE}\" and \"Conversion factor from capacity to activity unit PRC\\_CAPACT UTOPIA,SRE = 41.868\".\n",
      "\u001b[0m\n",
      "Response:\n",
      "\n",
      "<think>\n",
      "Okay, let me try to figure this out. The user is asking about \"passenger VKM\" in the model and why there's a conversion factor of 1.5 between PKM and something else.\n",
      "\n",
      "First, looking at the context provided. The example given is about the transport technology CAR. The activity of the process is in vehicle kilometers (VKM), while the commodity unit for TX1 is passenger kilometers (PKM). The capacity is in number of cars (NOC). \n",
      "\n",
      "The equations mention a conversion factor from activity unit to commodity unit as 1.5, which is PRC_ACTFLO UTOPIA, 2000,CAR,TX1 = 1.5. So, PKM is the commodity unit here. Since the activity is measured in VKM, and the commodity (TX1) uses PKM, there's a need to convert between these units. \n",
      "\n",
      "The question mentions \"passenger VKM\" but I think they might mean the relationship between VKM and PKM. The conversion factor 1.5 likely relates VKM to PKM. So, maybe for each VKM, you get 1.5 PKM? That would mean that for every kilometer a vehicle travels, it can carry passengers, and the factor accounts for how many passengers on average? Like if a car travels 1 VKM and carries 1.5 passengers on average, then PKM would be 1.5 times VKM. \n",
      "\n",
      "The context says the conversion factor from activity (VKM) to commodity unit (PKM) is 1.5. So the factor is used to convert the activity (vehicle km) into the actual commodity output (passenger km). So the 1.5 is the average number of passengers per vehicle kilometer. \n",
      "\n",
      "Therefore, the answer should explain that VKM is the activity unit (how much the vehicles are driven), PKM is the commodity (passenger transport), and the 1.5 conversion factor links them, probably representing passenger occupancy.\n",
      "</think>\n",
      "\n",
      "In the model, \"passenger VKM\" likely refers to the relationship between vehicle kilometers (VKM) and passenger kilometers (PKM). The activity unit for the process is measured in VKM, representing the distance traveled by vehicles, while the commodity (e.g., TX1) is measured in PKM, representing the transportation service provided to passengers. The conversion factor of 1.5 links these units, indicating that **1 VKM of vehicle activity yields 1.5 PKM of commodity output**. This reflects an assumed average occupancy or efficiency, such as 1.5 passengers per vehicle kilometer, converting the operational effort (VKM) into the delivered service (PKM). The factor ensures the model accounts for how vehicle usage translates into actual passenger transport.\n",
      "\n",
      "Source Nodes:\n",
      "----------------------------------\n",
      "Node ID: 83f7fe67-7399-4ded-a1bc-58dcd3ff49d6, Score: -4.29447078704834\n",
      "**Figure 3: Example of the definition of the capacity unit**\n",
      "\n",
      "It might occur that the unit in which the commodity(ies) of the primary commodity group are measured, is different from the activity unit. An example is shown in Figure 4. The activity of ...\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Node ID: a3fb65a8-a46c-4628-bfdd-d331d8dac1bf, Score: -4.306051254272461\n",
      "The car is labeled as \"Car CAR\" in the center of a rectangle. On the left side of the rectangle is \"DSL\" and \"Activity in 'vehicle kilometers' VKM\". On the right side of the rectangle is \"TX1\" and \"Commodity unit 'Passenger kilometers' PKM\". Below th...\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Node ID: db5392a3-c955-44e4-b872-2d7324027134, Score: -6.181003093719482\n",
      "p,cg,u) = {UTOPIA.CAR.TX1.PKM}\", \"Definition of capacity unit PRC\\_CAPUNT(r,p,cg,u) = {UTOPIA.CAR.TX1.NOC}\", \"Conversion factor from capacity to activity unit PRC\\_CAPACT UTOPIA, CAR = 10000\", and \"Conversion factor from activity unit to commodity un...\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Node ID: 1fc7ac40-c86d-48d6-8ab0-1bf1939079a2, Score: -9.703145980834961\n",
      "Since the capacity and activity units are different (mtoe for the capacity and PJ for the activity), the user has to supply the conversion factor from the energy unit embedded in the capacity unit to the activity unit. This is done by specifying the ...\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Node ID: 51f3a6d5-a76f-43c6-90e7-8b10cb7338ee, Score: -10.501738548278809\n",
      "An arrow points from \"Commodity group CG\\_SRE\" to the two blue lines. The image also includes the following text: \"Definition of capacity unit PRC\\_CAPUNT(r,p,cg,u) = {UTOPIA.SRE.CG\\_SRE.MTOE}\" and \"Conversion factor from capacity to activity unit PR...\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Query ---\n",
    "query = \"What does mean passenger VKM in the model? and why is raletd with the PKM with a convertion factor of 1.5\"\n",
    "response = query_engine.query(query)\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(response)\n",
    "\n",
    "print(\"\\nSource Nodes:\")\n",
    "for SourcedNode in response.source_nodes:\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"Node ID: {SourcedNode.node_id}, Score: {SourcedNode.score}\")\n",
    "    print(SourcedNode.text[:250] + \"...\") # Print snippet\n",
    "    # Check for parent node information in metadata\n",
    "    if 'parent_id' in SourcedNode.node.metadata:\n",
    "        print(f\"Parent Node ID: {SourcedNode.node.metadata['parent_id']}\")\n",
    "    print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cb7ac-cdce-48fb-ba0e-5716d9da803a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
